{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:50:51.769444Z",
     "start_time": "2018-01-30T22:50:51.764966Z"
    }
   },
   "outputs": [],
   "source": [
    "import glob, re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import *\n",
    "lbl = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:51:05.216825Z",
     "start_time": "2018-01-30T22:50:53.535581Z"
    }
   },
   "outputs": [],
   "source": [
    "#\"START HKLEE FEATURE\"\n",
    "dfs = { re.search('/([^/\\.]*)\\.csv', fn).group(1):\n",
    "    pd.read_csv(fn)for fn in glob.glob('../input/*.csv')}\n",
    "for k, v in dfs.items(): locals()[k] = v\n",
    "\n",
    "wkend_holidays = date_info.apply(lambda x: (x.day_of_week=='Sunday' or x.day_of_week=='Saturday') and x.holiday_flg==1, axis=1)\n",
    "date_info.loc[wkend_holidays, 'holiday_flg'] = 0\n",
    "date_info['weight'] = ((date_info.index + 1) / len(date_info)) ** 5  \n",
    "\n",
    "visit_data = air_visit_data.merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "visit_data.drop('calendar_date', axis=1, inplace=True)\n",
    "visit_data['visitors'] = visit_data.visitors.map(pd.np.log1p)\n",
    "\n",
    "visitors = visit_data.groupby(['air_store_id', 'day_of_week', 'holiday_flg']).apply(lambda x:( (x.weight * x.visitors).sum() / x.weight.sum() )).reset_index()\n",
    "visitors.rename(columns={0:'visitors'}, inplace=True) \n",
    "\n",
    "sample_submission['air_store_id'] = sample_submission.id.map(lambda x: '_'.join(x.split('_')[:-1]))\n",
    "sample_submission['calendar_date'] = sample_submission.id.map(lambda x: x.split('_')[2])\n",
    "sample_submission.drop('visitors', axis=1, inplace=True)\n",
    "sample_submission = sample_submission.merge(date_info, on='calendar_date', how='left')\n",
    "sample_submission = sample_submission.merge(visitors, on=['air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), how='left')['visitors_y'].values\n",
    "\n",
    "missings = sample_submission.visitors.isnull()\n",
    "sample_submission.loc[missings, 'visitors'] = sample_submission[missings].merge(visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "test_visit_var = sample_submission.visitors.map(pd.np.expm1)\n",
    "\n",
    "data = {\n",
    "    'tra': pd.read_csv('../input/air_visit_data.csv')\n",
    "    }\n",
    "\n",
    "data['tra'] = data['tra'].merge(date_info, left_on='visit_date', right_on='calendar_date', how='left')\n",
    "data['tra'] = data['tra'].merge(visitors, on=['air_store_id', 'day_of_week', 'holiday_flg'], how='left')\n",
    "\n",
    "missings = data['tra'].visitors_y.isnull()\n",
    "data['tra'].loc[missings, 'visitors_y'] = data['tra'][missings].merge(visitors[visitors.holiday_flg==0], on=('air_store_id', 'day_of_week'), how='left')['visitors_y'].values\n",
    "\n",
    "missings = data['tra'].visitors_y.isnull()\n",
    "data['tra'].loc[missings, 'visitors_y'] = data['tra'][missings].merge(visitors[['air_store_id', 'visitors']].groupby('air_store_id').mean().reset_index(), on='air_store_id', how='left')['visitors_y'].values\n",
    "\n",
    "train_visit_var = data['tra'].visitors_y.map(pd.np.expm1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:20.999770Z",
     "start_time": "2018-01-30T22:54:20.597991Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all the data\n",
    "air_visits = pd.read_csv('../input/air_visit_data.csv')\n",
    "air_reserve = pd.read_csv('../input/air_reserve.csv')\n",
    "air_store_info = pd.read_csv('../input/air_store_info.csv')\n",
    "hol = pd.read_csv('../input/date_info.csv').rename(columns={'calendar_date':'visit_date'})\n",
    "sample_submission = pd.read_csv('../input/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:22.542219Z",
     "start_time": "2018-01-30T22:54:21.414662Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer air_visits\n",
    "air_visits['visit_date'] = pd.to_datetime(air_visits['visit_date'])\n",
    "air_visits['dow'] = air_visits['visit_date'].dt.dayofweek\n",
    "air_visits['year'] = air_visits['visit_date'].dt.year\n",
    "air_visits['month'] = air_visits['visit_date'].dt.month\n",
    "air_visits['visit_date'] = air_visits['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:23.160329Z",
     "start_time": "2018-01-30T22:54:22.948715Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transfer sample submission\n",
    "sample_submission['visit_date'] = sample_submission['id'].map(lambda x:str(x).split('_')[2])\n",
    "sample_submission['air_store_id'] = sample_submission['id'].map(lambda x: '_'.join(str(x).split('_')[:2]))\n",
    "sample_submission['visit_date'] = pd.to_datetime(sample_submission['visit_date'])\n",
    "sample_submission['dow'] = sample_submission['visit_date'].dt.dayofweek\n",
    "sample_submission['year'] = sample_submission['visit_date'].dt.year\n",
    "sample_submission['month'] = sample_submission['visit_date'].dt.month\n",
    "sample_submission['visit_date'] = sample_submission['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:23.621374Z",
     "start_time": "2018-01-30T22:54:23.595693Z"
    }
   },
   "outputs": [],
   "source": [
    "unique_stores = sample_submission['air_store_id'].unique()\n",
    "stores = pd.concat([pd.DataFrame({'air_store_id': unique_stores, 'dow': [i]*len(unique_stores)}) for i in range(7)], axis=0, ignore_index=True).reset_index(drop=True)\n",
    "stores = pd.merge(stores, air_store_info, how='left', on=['air_store_id']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:24.174448Z",
     "start_time": "2018-01-30T22:54:24.165065Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEW FEATURES FROM Georgii Vyshnia\n",
    "stores['air_genre_name'] = stores['air_genre_name'].map(lambda x: str(str(x).replace('/',' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:24.719732Z",
     "start_time": "2018-01-30T22:54:24.605694Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    stores['air_genre_name'+str(i)] = lbl.fit_transform(stores['air_genre_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "for i in range(3):\n",
    "    stores['air_area_name'+str(i)] = lbl.fit_transform(stores['air_area_name'].map(lambda x: str(str(x).split(' ')[i]) if len(str(x).split(' '))>i else ''))\n",
    "\n",
    "stores['air_genre_name'] = lbl.fit_transform(stores['air_genre_name'])\n",
    "stores['air_area_name'] = lbl.fit_transform(stores['air_area_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:25.463165Z",
     "start_time": "2018-01-30T22:54:25.063189Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.merge(air_visits, stores, how='inner', on=['air_store_id','dow']) \n",
    "train['air_store_id2'] = lbl.fit_transform(train['air_store_id'])\n",
    "test = pd.merge(sample_submission, stores, how='inner', on=['air_store_id','dow']) \n",
    "test['air_store_id2'] = lbl.transform(test['air_store_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:25.706448Z",
     "start_time": "2018-01-30T22:54:25.580371Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(['visitors','dow','latitude', 'longitude'], axis=1, inplace=True)\n",
    "test.drop(['visitors','dow','visit_date','air_store_id', 'latitude', 'longitude'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:26.123350Z",
     "start_time": "2018-01-30T22:54:26.096603Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['hklee_feature'] = train_visit_var \n",
    "test['hklee_feature'] = test_visit_var\n",
    "train['weight'] = data['tra']['weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:33.210522Z",
     "start_time": "2018-01-30T22:54:27.372730Z"
    }
   },
   "outputs": [],
   "source": [
    "test.to_csv('test4.csv', index=False)\n",
    "train.to_csv('train4.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge with train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:56.131642Z",
     "start_time": "2018-01-30T22:54:49.121594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read all the data\n",
    "training = pd.read_csv('../train/training_data2.csv')\n",
    "val = pd.read_csv('../train/validation_data2.csv')\n",
    "testing = pd.read_csv('../train/submission_with_features2.csv')\n",
    "train = pd.read_csv('train4.csv')\n",
    "test = pd.read_csv('test4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:56.996621Z",
     "start_time": "2018-01-30T22:54:56.852839Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training.drop(['day_of_week','year', 'month', 'Friday', 'Monday',\n",
    "       'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'Apr', 'Aug',\n",
    "       'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep', 'air_genre_name', 'air_area_name',\n",
    "        'Asian', 'Bar Cocktail', 'Cafe Sweets', 'Creative cuisine',\n",
    "       'Dining bar', 'International cuisine', 'Italian French', 'Izakaya',\n",
    "       'Japanese food', 'Karaoke Party', 'Okonomiyaki Monja Teppanyaki',\n",
    "       'Other', 'Western food', 'Yakiniku Korean food', 'Fukuoka-ken',\n",
    "       'Hiroshima-ken', 'Hokkaidō', 'Hyōgo-ken', 'Miyagi-ken', 'Niigata-ken',\n",
    "       'Shizuoka-ken', 'Tōkyō-to', 'Ōsaka-fu'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "val.drop(['day_of_week','year', 'month', 'Friday', 'Monday',\n",
    "       'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'Apr', 'Aug',\n",
    "       'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep', 'air_genre_name', 'air_area_name',\n",
    "        'Asian', 'Bar Cocktail', 'Cafe Sweets', 'Creative cuisine',\n",
    "       'Dining bar', 'International cuisine', 'Italian French', 'Izakaya',\n",
    "       'Japanese food', 'Karaoke Party', 'Okonomiyaki Monja Teppanyaki',\n",
    "       'Other', 'Western food', 'Yakiniku Korean food', 'Fukuoka-ken',\n",
    "       'Hiroshima-ken', 'Hokkaidō', 'Hyōgo-ken', 'Miyagi-ken', 'Niigata-ken',\n",
    "       'Shizuoka-ken', 'Tōkyō-to', 'Ōsaka-fu'], axis=1, inplace=True)\n",
    "\n",
    "testing.drop(['day_of_week','year', 'month', 'Friday', 'Monday',\n",
    "       'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday', 'Apr', 'Aug',\n",
    "       'Dec', 'Feb', 'Jan', 'Jul', 'Jun', 'Mar', 'May', 'Nov', 'Oct', 'Sep', 'air_genre_name', 'air_area_name',\n",
    "        'Asian', 'Bar Cocktail', 'Cafe Sweets', 'Creative cuisine',\n",
    "       'Dining bar', 'International cuisine', 'Italian French', 'Izakaya',\n",
    "       'Japanese food', 'Karaoke Party', 'Okonomiyaki Monja Teppanyaki',\n",
    "       'Other', 'Western food', 'Yakiniku Korean food', 'Fukuoka-ken',\n",
    "       'Hiroshima-ken', 'Hokkaidō', 'Hyōgo-ken', 'Miyagi-ken', 'Niigata-ken',\n",
    "       'Shizuoka-ken', 'Tōkyō-to', 'Ōsaka-fu'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:54:58.773966Z",
     "start_time": "2018-01-30T22:54:58.124571Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training = pd.merge(training, train, how='left', on=['air_store_id', 'visit_date'])\n",
    "val = pd.merge(val, train, how='left', on=['air_store_id', 'visit_date'])\n",
    "testing = pd.merge(testing, test, how='left', on=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:55:18.810439Z",
     "start_time": "2018-01-30T22:54:59.507501Z"
    }
   },
   "outputs": [],
   "source": [
    "training.to_csv('training_data3.csv', index=False)\n",
    "val.to_csv('validation_data3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-30T22:55:21.416608Z",
     "start_time": "2018-01-30T22:55:18.813181Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testing.to_csv('submission_with_features3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "30px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
